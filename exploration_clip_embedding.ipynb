{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cab073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0016d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    data/photos/Le9rMdT8YFlvqr431LctIQ.jpg\n",
       "1    data/photos/zNzVcwnSJ4kvjFnANIsIRg.jpg\n",
       "2    data/photos/J1rqVl8pAoMJtPfGA2HV9w.jpg\n",
       "3    data/photos/56xUu0i5oOBj9GdZqIg9_w.jpg\n",
       "4    data/photos/GZpflvLA8AvQ6zi8aerdHg.jpg\n",
       "Name: photo_path, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"data/philly_restaurant_photos.json\"\n",
    "photo_data = pd.read_json(url, lines=True)\n",
    "\n",
    "\n",
    "photos_dir = Path(\"data/photos\")\n",
    "photo_data['photo_path'] = photo_data['photo_id'].apply(\n",
    "    lambda x: str(photos_dir / f\"{x}.jpg\")\n",
    ")\n",
    "\n",
    "photo_data['photo_path'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422680a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embedding(image_path, model, processor):\n",
    "    image = Image.open(image_path)\n",
    "    # preparer l'image et transformer en tenseur adapté à pytorch\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    # embdedding utilisant le modèle CLIP\n",
    "    with torch.no_grad():\n",
    "        image_features = model.get_image_features(**inputs)\n",
    "    # normalisation de l'embedding L2\n",
    "    return image_features / image_features.norm(p=2, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab85bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_photos_by_label(df, model, processor):\n",
    "    results = []\n",
    "    for (business_id, label), group in df.groupby(['business_id', 'label']):\n",
    "        embeddings= []\n",
    "\n",
    "        for idx, row in group.iterrows():\n",
    "            try : \n",
    "                embedding = get_image_embedding(row['photo_path'], model, processor)\n",
    "                embeddings.append(embedding[0].numpy())\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {row['photo_path']}: {e}\")\n",
    "                continue\n",
    "\n",
    "        if len(embeddings) > 0:\n",
    "            all_embs = np.stack(embeddings)\n",
    "            mean_emb = all_embs.mean(axis=0)\n",
    "            mean_emb = mean_emb / np.linalg.norm(mean_emb)\n",
    "            results.append({\n",
    "                'business_id': business_id,\n",
    "                'label': label,\n",
    "                'embedding': mean_emb\n",
    "            })\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729e2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embedding_batch(image_paths, model, processor, batch_size=32):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch_paths = image_paths[i:i+batch_size]\n",
    "        images = []\n",
    "        valid_indices = []\n",
    "        for idx, image_path in enumerate(batch_paths):\n",
    "            try:\n",
    "                image = Image.open(image_path)\n",
    "                images.append(image)\n",
    "                valid_indices.append(idx)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {image_path}: {e}\")\n",
    "                continue\n",
    "        if len(images) == 0:\n",
    "            continue\n",
    "        inputs = processor(images=images, return_tensors=\"pt\", padding=True)\n",
    "        with torch.no_grad():\n",
    "            image_features = model.get_image_features(**inputs)\n",
    "            image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)\n",
    "        all_embeddings.extend(image_features.numpy())\n",
    "    return np.array(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_photos_by_label_fast(df, model, processor, batch_size=32):\n",
    "    results = []\n",
    "    for (business_id, label), group in df.groupby(['business_id', 'label']):\n",
    "        image_paths = group['photo_path'].tolist()\n",
    "        embeddings = get_image_embedding_batch(image_paths, model, processor, batch_size)\n",
    "        if embeddings.shape[0] > 0:\n",
    "            mean_emb = embeddings.mean(axis=0)\n",
    "            mean_emb = mean_emb / np.linalg.norm(mean_emb)\n",
    "            results.append({\n",
    "                'business_id': business_id,\n",
    "                'label': label,\n",
    "                'embedding': mean_emb\n",
    "            })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182089e0",
   "metadata": {},
   "source": [
    "1. Pour chaque combinaison (business, label) :  \n",
    "    1. Pour chaque photo de ce groupe :  \n",
    "        - Extraire l'embedding  \n",
    "        - convertir en numpy  \n",
    "        - ajouter à la liste  \n",
    "    2. Empiler tous les embeddings  \n",
    "    3. Moyenner sur axe 0  \n",
    "    4. Normaliser   \n",
    "    5. Sauvegarder résultat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff1080b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image /Users/teatoscanduplantier/Desktop/ENSAE/Machine_Learning/Projet/Machine-learning-for-python/Etude_photos/photos/_-TxKgOJ6Oy0MinS88ntXg.jpg: [Errno 2] No such file or directory: '/Users/teatoscanduplantier/Desktop/ENSAE/Machine_Learning/Projet/Machine-learning-for-python/Etude_photos/photos/_-TxKgOJ6Oy0MinS88ntXg.jpg'\n"
     ]
    }
   ],
   "source": [
    "os.environ['HF_HUB_DOWNLOAD_TIMEOUT'] = '300'\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\", use_safetensors=True)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "embeddings_by_label = process_photos_by_label(photo_data, model, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58014647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id    label  \\\n",
      "0  -0M0b-XhtFagyLmsBtOe8w   inside   \n",
      "1  -0TffRSXXIlBYVbb5AwfTg    drink   \n",
      "2  -0TffRSXXIlBYVbb5AwfTg     food   \n",
      "3  -0TffRSXXIlBYVbb5AwfTg   inside   \n",
      "4  -0TffRSXXIlBYVbb5AwfTg  outside   \n",
      "\n",
      "                                           embedding  \n",
      "0  [0.009815368, -0.0013590974, 0.0011284378, -0....  \n",
      "1  [-0.011883101, 0.03936019, 0.017815243, 0.0007...  \n",
      "2  [0.013633062, 0.048887067, -0.0045891963, 0.01...  \n",
      "3  [-0.018343521, 0.02150698, 0.0011638484, 0.002...  \n",
      "4  [0.011479036, -0.057466, 0.06860343, -0.008981...  \n"
     ]
    }
   ],
   "source": [
    "print(embeddings_by_label.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec255a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "with open('embeddings_by_label.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings_by_label, f)\n",
    "\n",
    "embeddings_matrix = np.stack(embeddings_by_label['embedding'].values)\n",
    "np.save('embeddings_matrix.npy', embeddings_matrix)\n",
    "embeddings_by_label[['business_id', 'label']].to_csv('embeddings_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b943fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_by_label.to_csv('embeddings_by_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58e0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pondération qui s'adapte au nombre de labels présents\n",
    "def aggregate_to_business_normalized(embeddings_by_label_df): \n",
    "    base_weights = {\n",
    "        'food': 0.35,\n",
    "        'inside': 0.35,\n",
    "        'outside': 0.10,\n",
    "        'drink': 0.10,\n",
    "        'menu': 0.10\n",
    "    }\n",
    "    \n",
    "    business_embeddings = []\n",
    "    \n",
    "    for business_id in embeddings_by_label_df['business_id'].unique():\n",
    "        business_data = embeddings_by_label_df[\n",
    "            embeddings_by_label_df['business_id'] == business_id\n",
    "        ]\n",
    "        weighted_sum = np.zeros(512)\n",
    "        total_weight = 0\n",
    "        \n",
    "        for idx, row in business_data.iterrows():\n",
    "            label = row['label']\n",
    "            weight = base_weights.get(label, 0.1)\n",
    "            weighted_sum += row['embedding'] * weight\n",
    "            total_weight += weight  # Somme des poids réellement utilisés\n",
    "        \n",
    "        # Re-normaliser par la somme des poids actifs\n",
    "        if total_weight > 0:\n",
    "            final_emb = weighted_sum / total_weight  # ← Clé : division par total_weight\n",
    "            final_emb = final_emb / np.linalg.norm(final_emb)\n",
    "        else:\n",
    "            final_emb = np.zeros(512)\n",
    "        \n",
    "        business_embeddings.append({\n",
    "            'business_id': business_id,\n",
    "            'embedding': final_emb,\n",
    "            'n_labels': len(business_data),\n",
    "            'labels_present': ', '.join(business_data['label'].values)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(business_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21583c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id                                          embedding  \\\n",
      "0  -0M0b-XhtFagyLmsBtOe8w  [0.009815367254057478, -0.00135909736167944, 0...   \n",
      "1  -0TffRSXXIlBYVbb5AwfTg  [-0.0020635972460192956, 0.027889015327477534,...   \n",
      "2  -0eUa8TsXFFy0FCxHYmrjg  [0.03804909371904837, -0.0007548362063656802, ...   \n",
      "3  -1B9pP_CrRBJYPICE5WbRA  [-0.024990726315259223, 0.03304655852488704, 0...   \n",
      "4  -1b2kNOowsPrPpBOK4lNkQ  [-0.009722805816285285, 0.021325755452536156, ...   \n",
      "\n",
      "   n_labels                labels_present  \n",
      "0         1                        inside  \n",
      "1         4  drink, food, inside, outside  \n",
      "2         1                          food  \n",
      "3         2                  food, inside  \n",
      "4         2                  food, inside  \n"
     ]
    }
   ],
   "source": [
    "embeddings_by_business = aggregate_to_business_normalized(embeddings_by_label)\n",
    "print(embeddings_by_business.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13501cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_by_business.to_csv('embeddings_by_business.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
