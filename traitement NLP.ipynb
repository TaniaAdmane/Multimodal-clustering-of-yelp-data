{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87645914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import html\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1369ecd",
   "metadata": {},
   "source": [
    "## Traitement NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8497664e",
   "metadata": {},
   "source": [
    "Afin de réaliser l’embedding des avis, nous avons choisi d’utiliser SBERT. Ce modèle repose sur BERT, un encodeur Transformer, capable de capturer plusieurs couches d’information et donc les différentes nuances présentes dans un même texte. C’est particulièrement intéressant pour les avis Yelp, qui sont souvent riches et subjectifs.\n",
    "\n",
    "Notre objectif n’est pas d’identifier le type de nourriture, mais plutôt l’ambiance et les caractéristiques des restaurants. Or, avec des méthodes plus simples, ce sont généralement les mots liés à la cuisine qui ressortent le plus, au détriment de ces aspects plus subtils.\n",
    "\n",
    "Nous utilisons SBERT car, grâce au mécanisme de pooling, il est beaucoup plus rapide que BERT classique et directement adapté à la génération d’embeddings. D’après l’état de l’art, c’est aujourd’hui l’une des approches les plus efficaces pour représenter des textes courts comme des avis.\n",
    "\n",
    "Source : https://maartengr.github.io/BERTopic/getting_started/embeddings/embeddings.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dbe6ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(\"data/philly_restaurant_reviews.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "textes=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edbfcdff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5852.000000\n",
       "mean      117.445147\n",
       "std       247.806219\n",
       "min         5.000000\n",
       "25%        14.000000\n",
       "50%        40.000000\n",
       "75%       118.000000\n",
       "max      5778.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nombre d'avis par business\n",
    "nb_avis = textes.groupby(\"business_id\").size()\n",
    "nb_avis.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f0e9d",
   "metadata": {},
   "source": [
    "On choisit de garder la mediane comme nombre d'avis par restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4c244a",
   "metadata": {},
   "source": [
    "On garde un nettoyage leger, sbert fonctionnant le mieux sur des phrases à langage humain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b450f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nettoyer les données avant de les embedder\n",
    "def clean_data(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = html.unescape(text)\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \" \", text)\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "540cb9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# s'assurer que la colonne date est bien au format datetime\n",
    "textes[\"date\"] = pd.to_datetime(textes[\"date\"])\n",
    "textes[\"text_clean\"] = textes[\"text\"].apply(clean_data)\n",
    "\n",
    "textes_40 = (\n",
    "    textes\n",
    "    .sort_values(\"date\", ascending=False)   # du plus récent au plus ancien\n",
    "    .groupby(\"business_id\")\n",
    "    .head(40)                                # garder les 40 plus récents\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57629a74",
   "metadata": {},
   "source": [
    "Nous utilisons le transformer model \"all-MiniLM-L6-v2\" utilisé par Bertopic. Les embeddings sont d’abord calculés au niveau des avis individuels, puis agrégés au niveau du restaurant .Les embeddings sont normalisés afin de travailler dans un espace vectoriel comparable. Nous calculons ensuite la moyenne des embeddings des avis, ce qui permet d’obtenir une représentation globale du restaurant. Enfin, cette moyenne est à nouveau normalisée pour garantir une norme unitaire, ce qui facilite les comparaisons entre restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dc9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Embedder chaque avis individuellement, puis moyenner par restaurant\n",
    "print(\"Embedding des avis\")\n",
    "business_embeddings = []\n",
    "\n",
    "for business_id in textes_40['business_id'].unique():\n",
    "    business_reviews = textes_40[textes_40['business_id'] == business_id]['text_clean'].tolist()\n",
    "    review_embeddings = model.encode(\n",
    "        business_reviews,\n",
    "        batch_size=32,\n",
    "        show_progress_bar=True,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "    mean_embedding = review_embeddings.mean(axis=0)\n",
    "    mean_embedding = mean_embedding / np.linalg.norm(mean_embedding)\n",
    "\n",
    "    business_embeddings.append({\n",
    "        'business_id': business_id,\n",
    "        'embedding': mean_embedding,\n",
    "        'n_reviews': len(business_reviews)\n",
    "    })\n",
    "\n",
    "textes_restaurant = pd.DataFrame(business_embeddings)\n",
    "\n",
    "\n",
    "print(f\"Dimension des embeddings: {textes_restaurant['embedding'].iloc[0].shape}\")\n",
    "\n",
    "textes_restaurant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e5585",
   "metadata": {},
   "outputs": [],
   "source": [
    "textes_restaurant.to_csv('resultats_clustering_complet.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
